{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "edvdlpro3 machmaster.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9F25fJhU6Zi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "cfc61623-c889-4027-b2c9-c2473004a5c5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqC2s7S7VrQK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from numpy import array\n",
        "\n",
        "from numpy import zeros\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Embedding\n",
        "from keras_preprocessing.text import one_hot\n",
        "from numpy import asarray"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5JYWk5hVuQ_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a0779a78-d3d2-467d-eca5-1e6162c743b9"
      },
      "source": [
        "# define documents\n",
        "docs = [\n",
        "# non spam question\n",
        "\"Apparently cold showers are good for your skin and hair. How often should I take them? Once a day or twice a day?\",\n",
        "\"What are the articles that come from a famous journals and their content is to compare tow things and the writing model or writing skill is worth learning?\",\n",
        "\"In videos of North Korean military parades, they march with what appears to be a very exaggerated goose step. Is this their normal marching step?\",\n",
        "\"Frequently, part of my legs starts getting very itchy for no apparent reason and usually there will be an isolated hive/bump or a heat-rash-like condition. Does anyone know what causes this?\",\n",
        "\"What is your funniest road rage story? How did you get back at somebody who tailgated you, cut you off, etc.?\",\n",
        "\"Have you ever left a bad marriage for one you thought was going to be better, but it turned out to be even worse? Did you wish you had stayed with your first marriage? What happened?\"\n",
        "\"Why do boys not want to tell you if they have a crush on you?\",\n",
        "\"Can a lighter left in a jeans pocket in a crowded hamper be triggered and the butane cause the ink from the jeans' die to bleed onto clothes pressed against the pocket/lighter?\"\n",
        "#spam question\n",
        "\"Is there any woman (other than Muslim) who is happy after marrying a Muslim guy, as there are a lot of answers on Quora about love jihad, and all of them suffered a lot after marrying a Muslim guy?\",\n",
        "\"Why are South Indian dishes which are prepared by North Indians more tasty than dishes prepared by South Indian restaurants?\",\n",
        "\"AreÂ JatÂ andÂ GujjarÂ girls beautiful?\",\n",
        "\"Why do Americans need the second amendment? Don't want to start a fight but the right says it is necessary for a democracy and such and why are they so worried about the government.\",\n",
        "\"Can comrades of Quora answer, who are the IAS, IPS. IFS, IES officers that suffer due to their mentally retarded children?\",\n",
        "\"Why are Europeans so ungrateful for America? They'd be speaking German without us and because we cover their military costs, they can spend more on social safety programs.\",\n",
        "\"Are Vietnamese people one of the most hated races in the world?\",\n",
        "\"Why cant Indians stop comparing themselves with much developed countries and start working on building themselves instead?\"\n",
        "]\n",
        "# define class labels\n",
        "labels = array([0,0,0,0,0,0,0,1,1,1,1,1,1,1])\n",
        "labels.shape\n",
        "#reshaped_to_2d = np.reshape(labels, (-1, 2))\n",
        "#reshaped_to_2d.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-If90dm2Vzt-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5d913717-4013-41bc-eed7-6c4f1cbcfbf8"
      },
      "source": [
        "\n",
        "# prepare tokenizer\n",
        "t = Tokenizer()\n",
        "t.fit_on_texts(docs)\n",
        "vocab_size = len(t.word_index) + 1\n",
        "vocab_size"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "237"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQzTzNkYXlV3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e5055b91-6723-499e-e5ad-db407e34e5e0"
      },
      "source": [
        "# integer encode the documents\n",
        "encoded_docs = t.texts_to_sequences(docs)\n",
        "print(encoded_docs)\n",
        "encoded_docs\n",
        "#vocab_size\n",
        "#encoded_docs = [one_hot(d, vocab_size) for d in docs]\n",
        "#print(encoded_docs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[63, 64, 65, 4, 66, 11, 17, 67, 3, 68, 24, 69, 70, 71, 72, 25, 73, 1, 26, 18, 74, 1, 26], [12, 4, 2, 75, 27, 76, 28, 1, 77, 78, 3, 13, 79, 7, 6, 80, 81, 82, 3, 2, 29, 83, 18, 29, 84, 7, 85, 86], [14, 87, 8, 30, 88, 31, 89, 15, 90, 19, 12, 91, 6, 9, 1, 32, 92, 93, 33, 7, 34, 13, 94, 95, 33], [96, 97, 8, 98, 99, 100, 101, 32, 102, 11, 103, 104, 105, 3, 106, 20, 107, 9, 108, 109, 110, 111, 18, 1, 112, 113, 114, 115, 116, 117, 118, 12, 119, 34], [12, 7, 17, 120, 121, 122, 123, 24, 35, 5, 124, 125, 126, 127, 21, 128, 5, 129, 5, 130, 131], [36, 5, 132, 37, 1, 133, 38, 11, 39, 5, 134, 135, 136, 6, 9, 137, 40, 41, 138, 139, 6, 9, 140, 141, 35, 5, 142, 5, 143, 144, 19, 17, 145, 38, 12, 146, 10, 42, 147, 148, 43, 6, 149, 5, 150, 15, 36, 1, 151, 16, 5], [22, 1, 44, 37, 14, 1, 152, 45, 14, 1, 153, 154, 9, 155, 3, 2, 156, 157, 2, 158, 28, 2, 159, 160, 6, 161, 162, 163, 164, 165, 2, 45, 44, 7, 20, 166, 167, 168, 46, 23, 21, 7, 169, 47, 48, 1, 23, 49, 170, 20, 4, 1, 50, 8, 171, 16, 51, 52, 172, 173, 3, 174, 8, 25, 175, 1, 50, 47, 48, 1, 23, 49], [10, 4, 53, 54, 55, 176, 4, 56, 57, 30, 58, 59, 177, 46, 55, 56, 57, 53, 54, 178], [179, 180], [10, 42, 181, 182, 2, 183, 184, 185, 43, 6, 60, 1, 186, 40, 2, 187, 188, 41, 7, 189, 11, 1, 190, 3, 191, 3, 10, 4, 15, 61, 192, 52, 2, 193], [22, 194, 8, 51, 195, 21, 4, 2, 196, 197, 198, 199, 200, 27, 201, 202, 6, 13, 203, 204, 205], [10, 4, 206, 61, 207, 11, 208, 209, 9, 210, 211, 212, 213, 3, 214, 215, 216, 13, 31, 217, 15, 22, 218, 59, 16, 219, 220, 221], [4, 222, 223, 39, 8, 2, 224, 225, 226, 14, 2, 227], [10, 228, 58, 229, 230, 62, 19, 231, 232, 233, 3, 60, 234, 16, 235, 62, 236]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[63,\n",
              "  64,\n",
              "  65,\n",
              "  4,\n",
              "  66,\n",
              "  11,\n",
              "  17,\n",
              "  67,\n",
              "  3,\n",
              "  68,\n",
              "  24,\n",
              "  69,\n",
              "  70,\n",
              "  71,\n",
              "  72,\n",
              "  25,\n",
              "  73,\n",
              "  1,\n",
              "  26,\n",
              "  18,\n",
              "  74,\n",
              "  1,\n",
              "  26],\n",
              " [12,\n",
              "  4,\n",
              "  2,\n",
              "  75,\n",
              "  27,\n",
              "  76,\n",
              "  28,\n",
              "  1,\n",
              "  77,\n",
              "  78,\n",
              "  3,\n",
              "  13,\n",
              "  79,\n",
              "  7,\n",
              "  6,\n",
              "  80,\n",
              "  81,\n",
              "  82,\n",
              "  3,\n",
              "  2,\n",
              "  29,\n",
              "  83,\n",
              "  18,\n",
              "  29,\n",
              "  84,\n",
              "  7,\n",
              "  85,\n",
              "  86],\n",
              " [14,\n",
              "  87,\n",
              "  8,\n",
              "  30,\n",
              "  88,\n",
              "  31,\n",
              "  89,\n",
              "  15,\n",
              "  90,\n",
              "  19,\n",
              "  12,\n",
              "  91,\n",
              "  6,\n",
              "  9,\n",
              "  1,\n",
              "  32,\n",
              "  92,\n",
              "  93,\n",
              "  33,\n",
              "  7,\n",
              "  34,\n",
              "  13,\n",
              "  94,\n",
              "  95,\n",
              "  33],\n",
              " [96,\n",
              "  97,\n",
              "  8,\n",
              "  98,\n",
              "  99,\n",
              "  100,\n",
              "  101,\n",
              "  32,\n",
              "  102,\n",
              "  11,\n",
              "  103,\n",
              "  104,\n",
              "  105,\n",
              "  3,\n",
              "  106,\n",
              "  20,\n",
              "  107,\n",
              "  9,\n",
              "  108,\n",
              "  109,\n",
              "  110,\n",
              "  111,\n",
              "  18,\n",
              "  1,\n",
              "  112,\n",
              "  113,\n",
              "  114,\n",
              "  115,\n",
              "  116,\n",
              "  117,\n",
              "  118,\n",
              "  12,\n",
              "  119,\n",
              "  34],\n",
              " [12,\n",
              "  7,\n",
              "  17,\n",
              "  120,\n",
              "  121,\n",
              "  122,\n",
              "  123,\n",
              "  24,\n",
              "  35,\n",
              "  5,\n",
              "  124,\n",
              "  125,\n",
              "  126,\n",
              "  127,\n",
              "  21,\n",
              "  128,\n",
              "  5,\n",
              "  129,\n",
              "  5,\n",
              "  130,\n",
              "  131],\n",
              " [36,\n",
              "  5,\n",
              "  132,\n",
              "  37,\n",
              "  1,\n",
              "  133,\n",
              "  38,\n",
              "  11,\n",
              "  39,\n",
              "  5,\n",
              "  134,\n",
              "  135,\n",
              "  136,\n",
              "  6,\n",
              "  9,\n",
              "  137,\n",
              "  40,\n",
              "  41,\n",
              "  138,\n",
              "  139,\n",
              "  6,\n",
              "  9,\n",
              "  140,\n",
              "  141,\n",
              "  35,\n",
              "  5,\n",
              "  142,\n",
              "  5,\n",
              "  143,\n",
              "  144,\n",
              "  19,\n",
              "  17,\n",
              "  145,\n",
              "  38,\n",
              "  12,\n",
              "  146,\n",
              "  10,\n",
              "  42,\n",
              "  147,\n",
              "  148,\n",
              "  43,\n",
              "  6,\n",
              "  149,\n",
              "  5,\n",
              "  150,\n",
              "  15,\n",
              "  36,\n",
              "  1,\n",
              "  151,\n",
              "  16,\n",
              "  5],\n",
              " [22,\n",
              "  1,\n",
              "  44,\n",
              "  37,\n",
              "  14,\n",
              "  1,\n",
              "  152,\n",
              "  45,\n",
              "  14,\n",
              "  1,\n",
              "  153,\n",
              "  154,\n",
              "  9,\n",
              "  155,\n",
              "  3,\n",
              "  2,\n",
              "  156,\n",
              "  157,\n",
              "  2,\n",
              "  158,\n",
              "  28,\n",
              "  2,\n",
              "  159,\n",
              "  160,\n",
              "  6,\n",
              "  161,\n",
              "  162,\n",
              "  163,\n",
              "  164,\n",
              "  165,\n",
              "  2,\n",
              "  45,\n",
              "  44,\n",
              "  7,\n",
              "  20,\n",
              "  166,\n",
              "  167,\n",
              "  168,\n",
              "  46,\n",
              "  23,\n",
              "  21,\n",
              "  7,\n",
              "  169,\n",
              "  47,\n",
              "  48,\n",
              "  1,\n",
              "  23,\n",
              "  49,\n",
              "  170,\n",
              "  20,\n",
              "  4,\n",
              "  1,\n",
              "  50,\n",
              "  8,\n",
              "  171,\n",
              "  16,\n",
              "  51,\n",
              "  52,\n",
              "  172,\n",
              "  173,\n",
              "  3,\n",
              "  174,\n",
              "  8,\n",
              "  25,\n",
              "  175,\n",
              "  1,\n",
              "  50,\n",
              "  47,\n",
              "  48,\n",
              "  1,\n",
              "  23,\n",
              "  49],\n",
              " [10,\n",
              "  4,\n",
              "  53,\n",
              "  54,\n",
              "  55,\n",
              "  176,\n",
              "  4,\n",
              "  56,\n",
              "  57,\n",
              "  30,\n",
              "  58,\n",
              "  59,\n",
              "  177,\n",
              "  46,\n",
              "  55,\n",
              "  56,\n",
              "  57,\n",
              "  53,\n",
              "  54,\n",
              "  178],\n",
              " [179, 180],\n",
              " [10,\n",
              "  42,\n",
              "  181,\n",
              "  182,\n",
              "  2,\n",
              "  183,\n",
              "  184,\n",
              "  185,\n",
              "  43,\n",
              "  6,\n",
              "  60,\n",
              "  1,\n",
              "  186,\n",
              "  40,\n",
              "  2,\n",
              "  187,\n",
              "  188,\n",
              "  41,\n",
              "  7,\n",
              "  189,\n",
              "  11,\n",
              "  1,\n",
              "  190,\n",
              "  3,\n",
              "  191,\n",
              "  3,\n",
              "  10,\n",
              "  4,\n",
              "  15,\n",
              "  61,\n",
              "  192,\n",
              "  52,\n",
              "  2,\n",
              "  193],\n",
              " [22,\n",
              "  194,\n",
              "  8,\n",
              "  51,\n",
              "  195,\n",
              "  21,\n",
              "  4,\n",
              "  2,\n",
              "  196,\n",
              "  197,\n",
              "  198,\n",
              "  199,\n",
              "  200,\n",
              "  27,\n",
              "  201,\n",
              "  202,\n",
              "  6,\n",
              "  13,\n",
              "  203,\n",
              "  204,\n",
              "  205],\n",
              " [10,\n",
              "  4,\n",
              "  206,\n",
              "  61,\n",
              "  207,\n",
              "  11,\n",
              "  208,\n",
              "  209,\n",
              "  9,\n",
              "  210,\n",
              "  211,\n",
              "  212,\n",
              "  213,\n",
              "  3,\n",
              "  214,\n",
              "  215,\n",
              "  216,\n",
              "  13,\n",
              "  31,\n",
              "  217,\n",
              "  15,\n",
              "  22,\n",
              "  218,\n",
              "  59,\n",
              "  16,\n",
              "  219,\n",
              "  220,\n",
              "  221],\n",
              " [4, 222, 223, 39, 8, 2, 224, 225, 226, 14, 2, 227],\n",
              " [10, 228, 58, 229, 230, 62, 19, 231, 232, 233, 3, 60, 234, 16, 235, 62, 236]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pn7227O4XraT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 781
        },
        "outputId": "ff25b2ff-fcf3-4061-aeb7-b559ec2c7c06"
      },
      "source": [
        "# pad documents to a max length of 4 words\n",
        "import numpy as np\n",
        "max_length = 40\n",
        "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
        "print(padded_docs)\n",
        "padded_docs.shape\n",
        "#padded_docs.size\n",
        "#np.arange(560).reshape(16,35)\n",
        "#padded_docs.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 63  64  65   4  66  11  17  67   3  68  24  69  70  71  72  25  73   1\n",
            "   26  18  74   1  26   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0]\n",
            " [ 12   4   2  75  27  76  28   1  77  78   3  13  79   7   6  80  81  82\n",
            "    3   2  29  83  18  29  84   7  85  86   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0]\n",
            " [ 14  87   8  30  88  31  89  15  90  19  12  91   6   9   1  32  92  93\n",
            "   33   7  34  13  94  95  33   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0]\n",
            " [ 96  97   8  98  99 100 101  32 102  11 103 104 105   3 106  20 107   9\n",
            "  108 109 110 111  18   1 112 113 114 115 116 117 118  12 119  34   0   0\n",
            "    0   0   0   0]\n",
            " [ 12   7  17 120 121 122 123  24  35   5 124 125 126 127  21 128   5 129\n",
            "    5 130 131   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0]\n",
            " [135 136   6   9 137  40  41 138 139   6   9 140 141  35   5 142   5 143\n",
            "  144  19  17 145  38  12 146  10  42 147 148  43   6 149   5 150  15  36\n",
            "    1 151  16   5]\n",
            " [ 44   7  20 166 167 168  46  23  21   7 169  47  48   1  23  49 170  20\n",
            "    4   1  50   8 171  16  51  52 172 173   3 174   8  25 175   1  50  47\n",
            "   48   1  23  49]\n",
            " [ 10   4  53  54  55 176   4  56  57  30  58  59 177  46  55  56  57  53\n",
            "   54 178   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0]\n",
            " [179 180   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0]\n",
            " [ 10  42 181 182   2 183 184 185  43   6  60   1 186  40   2 187 188  41\n",
            "    7 189  11   1 190   3 191   3  10   4  15  61 192  52   2 193   0   0\n",
            "    0   0   0   0]\n",
            " [ 22 194   8  51 195  21   4   2 196 197 198 199 200  27 201 202   6  13\n",
            "  203 204 205   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0]\n",
            " [ 10   4 206  61 207  11 208 209   9 210 211 212 213   3 214 215 216  13\n",
            "   31 217  15  22 218  59  16 219 220 221   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0]\n",
            " [  4 222 223  39   8   2 224 225 226  14   2 227   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0]\n",
            " [ 10 228  58 229 230  62  19 231 232 233   3  60 234  16 235  62 236   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14, 40)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8eWDLP_YbHn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "outputId": "75005e46-e812-4aa8-83cd-b8de2a022428"
      },
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-06-13 06:11:51--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2020-06-13 06:11:51--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2020-06-13 06:11:51--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip.3’\n",
            "\n",
            "glove.6B.zip.3      100%[===================>] 822.24M  1.94MB/s    in 6m 29s  \n",
            "\n",
            "2020-06-13 06:18:21 (2.11 MB/s) - ‘glove.6B.zip.3’ saved [862182613/862182613]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tarB3xOYb6i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "67190aa9-be94-436d-90cb-6c9d5019213f"
      },
      "source": [
        "!unzip /content/glove.6B.zip.3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/glove.6B.zip.3\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j11Axl5ZXwAg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ad78fe5a-2ca8-42ee-ef18-3ce40ee61d63"
      },
      "source": [
        "\n",
        "# load the whole embedding into memory\n",
        "embeddings_index = dict()\n",
        "f = open('/content/glove.6B.100d.txt',mode='rt',encoding='utf-8')\n",
        "for line in f:\n",
        "\tvalues = line.split()\n",
        "\tword = values[0]\n",
        "\tcoefs = asarray(values[1:], dtype='float32')\n",
        "\tembeddings_index[word] = coefs\n",
        "f.close()\n",
        "print('Loaded %s word vectors.' % len(embeddings_index))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvqaGrjNaqV8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a weight matrix for words in training docs\n",
        "embedding_matrix = zeros((vocab_size, 100))\n",
        "for word, i in t.word_index.items():\n",
        "\tembedding_vector = embeddings_index.get(word)\n",
        "\tif embedding_vector is not None:\n",
        "\t\tembedding_matrix[i] = embedding_vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExALLzKxa5-K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define model\n",
        "model = Sequential()\n",
        "e = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=40, trainable=False)\n",
        "model.add(e)\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMmMI6bJoPaz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFYp0H9coTgv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "f03c9971-51fa-4808-fa28-77034f450ec1"
      },
      "source": [
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 40, 100)           23700     \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 4000)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 4001      \n",
            "=================================================================\n",
            "Total params: 27,701\n",
            "Trainable params: 4,001\n",
            "Non-trainable params: 23,700\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KCNs2ZkoXq2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c929231e-883d-4fc8-d96b-1f0e6b9dc446"
      },
      "source": [
        "model.fit(padded_docs, labels, epochs=50, verbose=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7fa164976748>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFmUkvojJyii",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b1689dec-0f20-4a17-dcec-b23bd3e5aaa2"
      },
      "source": [
        "loss, accuracy = model.evaluate(padded_docs, labels, verbose=0)\n",
        "print('Accuracy: %f' % (accuracy*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 100.000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hsh6pXIDQ-D7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('/content/drive/My Drive/Colab Notebooks/edvProj_3DL.h5')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}